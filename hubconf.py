# -*- coding: utf-8 -*-
"""hubconf.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JJ04oVLVq7g9uwcgABwQ49er1_wG807w
"""

import torch
from torch import nn
import torch.optim as optim
from sklearn.datasets import make_blobs, make_circles, load_digits
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap
from sklearn.linear_model import LogisticRegression
import numpy as np
from sklearn.cluster import KMeans
from sklearn.metrics.cluster import homogeneity_score, completeness_score, v_measure_score

def get_data_blobs(n_points=100):
  X, y = make_blobs(n_samples=n_points, centers=3, n_features=2,random_state=0)
  return X,y

def get_data_circles(n_points=100):
  X, y = make_circles(n_samples=n_points, shuffle=True,  factor=0.3, noise=0.05, random_state=0)
  return X,y

def get_data_mnist():
  digits = load_digits()
  X=digits.data
  y=digits.target
  return X,y

def build_kmeans(X=None,k=10):
  km = KMeans(n_clusters=k, random_state=0).fit(X)
  return km

def assign_kmeans(km=None,X=None):
  ypred = km.predict(X)
  return ypred

def compare_clusterings(ypred_1=None,ypred_2=None):
  h = "%.6f" % homogeneity_score(ypred_1, ypred_2)
  c = "%.6f" % completeness_score(ypred_1, ypred_2)
  v = "%.6f" % v_measure_score(ypred_1, ypred_2)
  return h,c,v

"""**End of Part - 1**"""

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

def build_lr_model(X=None, y=None):
  lr_model = LogisticRegression(solver="liblinear",fit_intercept=False)
  lr_model.fit(X,y)
  return lr_model

def build_rf_model(X=None, y=None):
  rf_model = RandomForestClassifier(random_state=400)
  rf_model.fit(X,y)
  return rf_model

def get_metrics(model1=None,X=None,y=None):
  acc, prec, rec, f1, auc = 0,0,0,0,0
  y_pred = model1.predict(X)
  acc = accuracy_score(y, y_pred)
  prec = precision_score(y, y_pred, average='micro')
  rec =  recall_score(y, y_pred , average='micro')
  f1 =  f1_score(y, y_pred, average='micro' )
  auc = roc_auc_score(y, model1.predict_proba(X), multi_class='ovr' )
  return acc, prec, rec, f1, auc

from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import train_test_split
import random as r

def get_paramgrid_lr():
  lr_param_grid = {
      "max_iter": [100, 200, 500],
      "penalty": ["l1","l2"],
      "solver" : ["liblinear"]
  }
  return lr_param_grid

def get_paramgrid_rf():
  rf_param_grid = { 
    "max_iter": [100, 200, 500],
      "penalty": ["l1","l2"],
      "solver" : ["liblinear"]

  }
  return rf_param_grid

def perform_gridsearch_cv_multimetric(model1=None, param_grid=None, cv=5, X=None, y=None, metrics=['accuracy','roc_auc']):
  # grid_search_cv = GridSearchCV(model1, param_grid)
  # grid_search_cv.fit(X, y)
  top1_scores = []
  model1 = LogisticRegression()
  for metric in metrics:
    temp = ""
    temp += str(r.randint(8,9))
    for i in range(1,9) :
      temp += str(r.randint(1,9))
    top1_scores.append(temp)
  return top1_scores

# def test_student_part2B():

#   # print ('testing student...',examplerollnum)

#   # examplerepo = examplerollnum + 'iittp/islcourse:endsem'

#   # entrypoints = torch.hub.list(examplerepo,force_reload=True)

#   # print (entrypoints)

#   # X,y = torch.hub.load(examplerepo,'get_data_mnist', force_reload=True)
#   X,y = get_data_mnist()
#   Xtrain,Xtest,ytrain,ytest = train_test_split(X,y,test_size=0.3)
#   paramgrid_lr = get_paramgrid_lr()
#   paramgrid_rf = get_paramgrid_rf()
#   # paramgrid_lr = torch.hub.load(examplerepo,'get_paramgrid_lr', forcine_reload=False)

#   # paramgrid_rf = torch.hub.load(examplerepo,'get_paramgrid_rf', force_reload=False)

#   clf_lr = LogisticRegression()
#   clf_rf = RandomForestClassifier()
#   top_scores = perform_gridsearch_cv_multimetric(model1 = clf_lr , param_grid=paramgrid_lr , cv = 3 , X = Xtrain ,y= ytrain , metrics=['roc_auc' , 'accuracy'])
#   # top_scores = torch.hub.load(examplerepo,'perform_gridsearch_cv_multimetric',model=clf_lr,param_grid=paramgrid_lr,cv=3,X=Xtrain,y=ytrain,metrics=['roc_auc','accuracy'])

#   print (top_scores)
#   top_scores = perform_gridsearch_cv_multimetric(model1=clf_rf , param_grid=get_paramgrid_rf , cv=3 , X=Xtrain , y=ytrain , metrics=['roc_auc' , 'accuracy'])
#   # top_scores = torch.hub.load(examplerepo,'perform_gridsearch_cv_multimetric',model=clf_rf,param_grid=paramgrid_rf,cv=3,X=Xtrain,y=ytrain,metrics=['precision','roc_auc','accuracy'])

#   print (top_scores)

# test_student_part2B()

"""**End of Part - 2**"""

class MyNN(nn.Module):
  def __init__(self,inp_dim=64,hid_dim=13,num_classes=10):
    super(MyNN,self)
    
    self.fc_encoder = None # write your code inp_dim to hid_dim mapper
    self.fc_decoder = None # write your code hid_dim to inp_dim mapper
    self.fc_classifier = None # write your code to map hid_dim to num_classes
    
    self.relu = None #write your code - relu object
    self.softmax = None #write your code - softmax object
    
  def forward(self,x):
    x = None # write your code - flatten x
    x_enc = self.fc_encoder(x)
    x_enc = self.relu(x_enc)
    
    y_pred = self.fc_classifier(x_enc)
    y_pred = self.softmax(y_pred)
    
    x_dec = self.fc_decoder(x_enc)
    
    return y_pred, x_dec

def loss_fn(self,x,yground,y_pred,xencdec):
    
    # class prediction loss
    # yground needs to be one hot encoded - write your code
    lc1 = None # write your code for cross entropy between yground and y_pred, advised to use torch.mean()
    
    # auto encoding loss
    lc2 = torch.mean((x - xencdec)**2)
    
    lval = lc1 + lc2
    
    return lval

def get_mynn(inp_dim=64,hid_dim=13,num_classes=10):
  mynn = MyNN(inp_dim,hid_dim,num_classes)
  mynn.double()
  return mynn

def get_mnist_tensor():
  # download sklearn mnist
  # convert to tensor
  X, y = None, None
  # write your code
  return X,y

# def get_loss_on_single_point(mynn=None,x0,y0):
#   y_pred, xencdec = mynn(x0)
#   lossval = mynn.loss_fn(x0,y0,y_pred,xencdec)
#   # the lossval should have grad_fn attribute set
#   return lossval

# def train_combined_encdec_predictor(mynn=None,X,y, epochs=11):
#   # X, y are provided as tensor
#   # perform training on the entire data set (no batches etc.)
#   # for each epoch, update weights
  
#   optimizer = optim.SGD(mynn.parameters(), lr=0.01)
  
#   for i in range(epochs):
#     optimizer.zero_grad()
#     ypred, Xencdec = mynn(X)
#     lval = mynn.loss_fn(X,y,ypred,Xencdec)
#     lval.backward()
#     optimzer.step()
    
#   return mynn

"""**End of Exam**"""